#!/usr/bin/env python3
"""
å¤§æ¨¡å‹æœ¬åœ°åŒ–ç³»ç»Ÿä½¿ç”¨ç¤ºä¾‹
ç›´æ¥è°ƒç”¨å·²éƒ¨ç½²çš„APIæœåŠ¡
"""

import requests
import json
import time

# APIåŸºç¡€URL
BASE_URL = "http://localhost:8000/api/v1"

def test_health():
    """æµ‹è¯•æœåŠ¡å¥åº·çŠ¶æ€"""
    try:
        response = requests.get(f"{BASE_URL}/health")
        print(f"âœ… æœåŠ¡çŠ¶æ€: {response.json()}")
        return True
    except Exception as e:
        print(f"âŒ æœåŠ¡è¿æ¥å¤±è´¥: {e}")
        return False

def get_available_models():
    """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
    try:
        response = requests.get(f"{BASE_URL}/models")
        models = response.json()
        print(f"ğŸ“‹ å¯ç”¨æ¨¡å‹: {models}")
        return models
    except Exception as e:
        print(f"âŒ è·å–æ¨¡å‹å¤±è´¥: {e}")
        return []

def chat_with_model(message, stream=False):
    """ä¸æ¨¡å‹å¯¹è¯"""
    try:
        data = {
            "messages": [{"role": "user", "content": message}],
            "stream": stream
        }
        
        if stream:
            # æµå¼å“åº”
            response = requests.post(f"{BASE_URL}/chat/stream", 
                                   json=data, stream=True)
            print("ğŸ¤– æ¨¡å‹å›å¤ï¼ˆæµå¼ï¼‰:")
            for line in response.iter_lines():
                if line:
                    try:
                        chunk = json.loads(line.decode('utf-8'))
                        if chunk.get('content'):
                            print(chunk['content'], end='', flush=True)
                    except:
                        continue
            print("\n")
        else:
            # æ™®é€šå“åº”
            response = requests.post(f"{BASE_URL}/chat", json=data)
            result = response.json()
            print(f"ğŸ¤– æ¨¡å‹å›å¤: {result['message']}")
            return result['message']
            
    except Exception as e:
        print(f"âŒ å¯¹è¯å¤±è´¥: {e}")
        return None

def get_system_info():
    """è·å–ç³»ç»Ÿä¿¡æ¯"""
    try:
        response = requests.get(f"{BASE_URL}/system/info")
        info = response.json()
        print(f"ğŸ’» ç³»ç»Ÿä¿¡æ¯: {json.dumps(info, indent=2, ensure_ascii=False)}")
        return info
    except Exception as e:
        print(f"âŒ è·å–ç³»ç»Ÿä¿¡æ¯å¤±è´¥: {e}")
        return None

def get_gpu_info():
    """è·å–GPUä¿¡æ¯"""
    try:
        response = requests.get(f"{BASE_URL}/computing/gpus")
        gpus = response.json()
        print(f"ğŸ® GPUä¿¡æ¯: {json.dumps(gpus, indent=2, ensure_ascii=False)}")
        return gpus
    except Exception as e:
        print(f"âŒ è·å–GPUä¿¡æ¯å¤±è´¥: {e}")
        return None

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¤§æ¨¡å‹æœ¬åœ°åŒ–ç³»ç»Ÿä½¿ç”¨ç¤ºä¾‹")
    print("=" * 50)
    
    # 1. æ£€æŸ¥æœåŠ¡çŠ¶æ€
    print("\n1. æ£€æŸ¥æœåŠ¡çŠ¶æ€...")
    if not test_health():
        print("âŒ æœåŠ¡æœªè¿è¡Œï¼Œè¯·å…ˆå¯åŠ¨æœåŠ¡")
        return
    
    # 2. è·å–å¯ç”¨æ¨¡å‹
    print("\n2. è·å–å¯ç”¨æ¨¡å‹...")
    models = get_available_models()
    
    # 3. è·å–ç³»ç»Ÿä¿¡æ¯
    print("\n3. è·å–ç³»ç»Ÿä¿¡æ¯...")
    get_system_info()
    
    # 4. è·å–GPUä¿¡æ¯
    print("\n4. è·å–GPUä¿¡æ¯...")
    get_gpu_info()
    
    # 5. ä¸æ¨¡å‹å¯¹è¯
    print("\n5. ä¸æ¨¡å‹å¯¹è¯...")
    
    # æ™®é€šå¯¹è¯
    print("\nğŸ“ æ™®é€šå¯¹è¯:")
    chat_with_model("ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±")
    
    # æµå¼å¯¹è¯
    print("\nğŸ“ æµå¼å¯¹è¯:")
    chat_with_model("è¯·å†™ä¸€é¦–å…³äºAIçš„è¯—", stream=True)
    
    # 6. äº¤äº’å¼å¯¹è¯
    print("\n6. äº¤äº’å¼å¯¹è¯æ¨¡å¼")
    print("è¾“å…¥ 'quit' é€€å‡º")
    
    while True:
        try:
            user_input = input("\nğŸ‘¤ ä½ : ")
            if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
                break
            
            if user_input.strip():
                chat_with_model(user_input)
                
        except KeyboardInterrupt:
            print("\nğŸ‘‹ å†è§ï¼")
            break
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")

if __name__ == "__main__":
    main()
